{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Neural Networks - Code Exercise\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910af33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "LESSON 10: BUILDING A NEURAL NETWORK FOR FASHIONMNIST\n",
    "================================================================================\n",
    "\n",
    "This lesson brings together everything we've learned to build a real image\n",
    "classifier! We'll use the FashionMNIST dataset to classify clothing items.\n",
    "\n",
    "FashionMNIST is a dataset of 70,000 grayscale images of clothing items:\n",
    "- 60,000 training images\n",
    "- 10,000 test images\n",
    "- Each image is 28x28 pixels\n",
    "- 10 different clothing categories\n",
    "\n",
    "This is the CAPSTONE of our PyTorch fundamentals course!\n",
    "\n",
    "Key concepts covered:\n",
    "1. Loading real-world image datasets\n",
    "2. Data preprocessing and normalization\n",
    "3. Building a multi-layer neural network\n",
    "4. Training loop with progress tracking\n",
    "5. Evaluation and accuracy metrics\n",
    "6. Visualization of results\n",
    "7. Making predictions on new data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LESSON 10: BUILDING A NEURAL NETWORK FOR FASHIONMNIST\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nStarting lesson at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae7bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dacb4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 1: UNDERSTANDING THE DATASET\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f30e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "FashionMNIST Dataset Overview:\n",
    "------------------------------\n",
    "This dataset was created by Zalando Research as a more challenging replacement\n",
    "for the classic MNIST handwritten digits dataset. Instead of digits (0-9),\n",
    "we have 10 categories of clothing items.\n",
    "\n",
    "Why FashionMNIST?\n",
    "- Same format as MNIST (28x28 grayscale images)\n",
    "- More challenging - clothing items have more variation than digits\n",
    "- Real-world application - image classification for e-commerce\n",
    "- Perfect size for learning - not too big, not too simple\n",
    "\n",
    "Dataset Statistics:\n",
    "- Total images: 70,000\n",
    "- Training set: 60,000 images\n",
    "- Test set: 10,000 images\n",
    "- Image size: 28 \u00d7 28 pixels\n",
    "- Channels: 1 (grayscale)\n",
    "- Classes: 10 clothing categories\n",
    "- Each class has exactly 6,000 training images and 1,000 test images\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb13bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 10 class names\n",
    "class_names = [\n",
    "    'T-shirt/top',  # Class 0\n",
    "    'Trouser',      # Class 1\n",
    "    'Pullover',     # Class 2\n",
    "    'Dress',        # Class 3\n",
    "    'Coat',         # Class 4\n",
    "    'Sandal',       # Class 5\n",
    "    'Shirt',        # Class 6\n",
    "    'Sneaker',      # Class 7\n",
    "    'Bag',          # Class 8\n",
    "    'Ankle boot'    # Class 9\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac22d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The 10 clothing categories:\")\n",
    "print(\"-\" * 40)\n",
    "for idx, name in enumerate(class_names):\n",
    "    print(f\"  {idx}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 2: LOADING AND PREPROCESSING THE DATASET\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e478fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Data Preprocessing Steps:\n",
    "--------------------------\n",
    "1. ToTensor(): Converts PIL Image or numpy array to PyTorch tensor\n",
    "   - Changes shape from (H, W, C) to (C, H, W)\n",
    "   - Scales pixel values from [0, 255] to [0.0, 1.0]\n",
    "\n",
    "2. Normalize(): Standardizes the data\n",
    "   - Formula: output = (input - mean) / std\n",
    "   - For FashionMNIST: mean=0.5, std=0.5\n",
    "   - This scales values from [0, 1] to [-1, 1]\n",
    "\n",
    "Why normalize?\n",
    "- Helps the neural network train faster\n",
    "- Makes gradient descent more stable\n",
    "- Prevents certain features from dominating due to scale\n",
    "- Centers the data around zero (ideal for neural networks)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eba1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transforms to apply to the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),           # Convert to tensor and scale to [0, 1]\n",
    "    transforms.Normalize((0.5,),     # Mean for single channel (grayscale)\n",
    "                        (0.5,))      # Std for single channel\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d683b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating data transform pipeline:\")\n",
    "print(\"  1. ToTensor() - Convert images to tensors\")\n",
    "print(\"  2. Normalize(mean=0.5, std=0.5) - Standardize pixel values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data directory\n",
    "data_dir = '/Users/zack/dev/ml-refresher/data/fashionmnist'\n",
    "print(f\"\\nData will be stored in: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398a0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDownloading and loading training dataset...\")\n",
    "print(\"(This may take a moment on first run - dataset is ~30MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3a4e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    root=data_dir,\n",
    "    train=True,           # Load training data\n",
    "    download=True,        # Download if not present\n",
    "    transform=transform   # Apply our preprocessing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f216f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\u2713 Training dataset loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDownloading and loading test dataset...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60349613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=data_dir,\n",
    "    train=False,          # Load test data\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad44b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\u2713 Test dataset loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2167dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print dataset information\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Dataset Information:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Training samples: {len(train_dataset):,}\")\n",
    "print(f\"Test samples: {len(test_dataset):,}\")\n",
    "print(f\"Total samples: {len(train_dataset) + len(test_dataset):,}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine a single sample\n",
    "sample_image, sample_label = train_dataset[0]\n",
    "print(f\"\\nSample image tensor shape: {sample_image.shape}\")\n",
    "print(f\"  - Channels: {sample_image.shape[0]} (grayscale)\")\n",
    "print(f\"  - Height: {sample_image.shape[1]} pixels\")\n",
    "print(f\"  - Width: {sample_image.shape[2]} pixels\")\n",
    "print(f\"Sample label: {sample_label} ({class_names[sample_label]})\")\n",
    "print(f\"Pixel value range: [{sample_image.min():.3f}, {sample_image.max():.3f}]\")\n",
    "print(\"  (Values are normalized to roughly [-1, 1])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b934e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 3: VISUALIZING SAMPLE IMAGES\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e4e3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Let's visualize some sample images to understand what we're working with.\n",
    "This helps us verify the data loaded correctly and understand the task.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure to show sample images\n",
    "fig, axes = plt.subplots(3, 5, figsize=(12, 7))\n",
    "fig.suptitle('FashionMNIST Sample Images', fontsize=16, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDisplaying 15 random training samples...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f716479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, ax in enumerate(axes.flat):\n",
    "    # Get a random sample\n",
    "    random_idx = np.random.randint(len(train_dataset))\n",
    "    image, label = train_dataset[random_idx]\n",
    "\n",
    "    # Convert from (C, H, W) to (H, W) for display\n",
    "    image = image.squeeze()  # Remove channel dimension\n",
    "\n",
    "    # Denormalize for visualization: reverse the (x - 0.5) / 0.5 transform\n",
    "    # If x_norm = (x - 0.5) / 0.5, then x = x_norm * 0.5 + 0.5\n",
    "    image = image * 0.5 + 0.5  # Scale from [-1, 1] back to [0, 1]\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(f'{class_names[label]}', fontsize=9)\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cb912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "sample_path = os.path.join(data_dir, 'sample_images.png')\n",
    "plt.savefig(sample_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"\u2713 Sample images saved to: {sample_path}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea786607",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4: CREATING DATA LOADERS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f508a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "DataLoaders wrap our datasets and provide:\n",
    "------------------------------------------\n",
    "1. Batching: Group samples into batches for efficient training\n",
    "   - Instead of processing 1 image at a time, we process 64 at once\n",
    "   - GPU parallelization works much better with batches\n",
    "\n",
    "2. Shuffling: Randomize the order of samples\n",
    "   - Prevents the model from learning the order of examples\n",
    "   - Helps the model generalize better\n",
    "   - Only shuffle training data (not test data)\n",
    "\n",
    "3. Automatic iteration: Easy to loop through batches\n",
    "   - Handles the complexity of batching automatically\n",
    "   - Loads data in the background (can use multiple workers)\n",
    "\n",
    "Batch Size Choice:\n",
    "- Larger batches (128, 256): Faster training, more memory\n",
    "- Smaller batches (32, 64): Slower training, less memory, sometimes better generalization\n",
    "- We'll use 64 as a good middle ground\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89407c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "print(f\"Setting batch_size = {batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for training data\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,        # Shuffle training data\n",
    "    num_workers=0        # Use main process (set to 2-4 for faster loading)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c78a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for test data\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,       # Don't shuffle test data (order doesn't matter)\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"DataLoader Information:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"  ({len(train_dataset)} samples \u00f7 {batch_size} batch_size = \"\n",
    "      f\"{len(train_dataset) / batch_size:.1f} batches)\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "print(f\"  ({len(test_dataset)} samples \u00f7 {batch_size} batch_size = \"\n",
    "      f\"{len(test_dataset) / batch_size:.1f} batches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch to examine the shape\n",
    "sample_batch_images, sample_batch_labels = next(iter(train_loader))\n",
    "print(f\"\\nSample batch shapes:\")\n",
    "print(f\"  Images: {sample_batch_images.shape}\")\n",
    "print(f\"    - Batch size: {sample_batch_images.shape[0]} images\")\n",
    "print(f\"    - Channels: {sample_batch_images.shape[1]} (grayscale)\")\n",
    "print(f\"    - Height: {sample_batch_images.shape[2]} pixels\")\n",
    "print(f\"    - Width: {sample_batch_images.shape[3]} pixels\")\n",
    "print(f\"  Labels: {sample_batch_labels.shape}\")\n",
    "print(f\"    - {sample_batch_labels.shape[0]} labels (one per image)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87df13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 5: BUILDING THE NEURAL NETWORK\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce21a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Network Architecture:\n",
    "---------------------\n",
    "We're building a feedforward neural network (also called a Multi-Layer Perceptron).\n",
    "\n",
    "Structure:\n",
    "    Input (28\u00d728 image)\n",
    "        \u2193 Flatten\n",
    "    784 neurons\n",
    "        \u2193 Linear + ReLU\n",
    "    512 neurons (Hidden Layer 1)\n",
    "        \u2193 Linear + ReLU\n",
    "    256 neurons (Hidden Layer 2)\n",
    "        \u2193 Linear\n",
    "    10 neurons (Output - one per class)\n",
    "\n",
    "Why this architecture?\n",
    "----------------------\n",
    "1. Flatten: Neural networks expect 1D input vectors\n",
    "   - Converts 28\u00d728 image into 784-length vector\n",
    "\n",
    "2. First Hidden Layer (784 \u2192 512):\n",
    "   - Learns basic patterns from raw pixels\n",
    "   - 512 neurons provide enough capacity to learn\n",
    "\n",
    "3. Second Hidden Layer (512 \u2192 256):\n",
    "   - Learns higher-level combinations of patterns\n",
    "   - Gradual decrease helps the network learn hierarchy\n",
    "\n",
    "4. Output Layer (256 \u2192 10):\n",
    "   - 10 outputs (one per class)\n",
    "   - Raw scores called \"logits\"\n",
    "   - Higher score = model more confident that class is correct\n",
    "\n",
    "ReLU Activation Function:\n",
    "--------------------------\n",
    "ReLU(x) = max(0, x)\n",
    "- Keeps positive values unchanged\n",
    "- Sets negative values to zero\n",
    "- Introduces non-linearity (crucial for learning complex patterns)\n",
    "- Fast to compute and train\n",
    "- Helps prevent vanishing gradient problem\n",
    "\n",
    "Why not use activation on output?\n",
    "- CrossEntropyLoss expects raw logits (unnormalized scores)\n",
    "- It applies softmax internally for efficiency\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network for FashionMNIST Classification\n",
    "\n",
    "    Architecture:\n",
    "    - Input: 28x28 grayscale images (flattened to 784)\n",
    "    - Hidden Layer 1: 512 neurons with ReLU activation\n",
    "    - Hidden Layer 2: 256 neurons with ReLU activation\n",
    "    - Output Layer: 10 neurons (one per class)\n",
    "\n",
    "    Total Parameters: ~400,000 (we'll calculate this below)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FashionNN, self).__init__()\n",
    "\n",
    "        # Flatten layer - converts 2D image to 1D vector\n",
    "        # Input: (batch_size, 1, 28, 28)\n",
    "        # Output: (batch_size, 784)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # First hidden layer - learn basic features\n",
    "        # Input: 784 (28 * 28 pixels)\n",
    "        # Output: 512 neurons\n",
    "        # Parameters: (784 * 512) + 512 = 401,920\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "\n",
    "        # Second hidden layer - learn combinations of features\n",
    "        # Input: 512 neurons\n",
    "        # Output: 256 neurons\n",
    "        # Parameters: (512 * 256) + 256 = 131,328\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "\n",
    "        # Output layer - map to 10 classes\n",
    "        # Input: 256 neurons\n",
    "        # Output: 10 neurons (one per class)\n",
    "        # Parameters: (256 * 10) + 10 = 2,570\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "        # ReLU activation function\n",
    "        # We'll apply this after fc1 and fc2\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, 1, 28, 28)\n",
    "\n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size, 10) containing logits\n",
    "        \"\"\"\n",
    "        # Print shapes for educational purposes (only for first call)\n",
    "        if not hasattr(self, '_shapes_printed'):\n",
    "            print(\"\\n\" + \"-\" * 60)\n",
    "            print(\"Forward Pass - Tensor Shapes:\")\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"Input shape: {x.shape}\")\n",
    "            self._shapes_printed = True\n",
    "\n",
    "        # Step 1: Flatten the image from 2D to 1D\n",
    "        # (batch_size, 1, 28, 28) \u2192 (batch_size, 784)\n",
    "        x = self.flatten(x)\n",
    "        if hasattr(self, '_shapes_printed') and self._shapes_printed:\n",
    "            print(f\"After flatten: {x.shape}\")\n",
    "\n",
    "        # Step 2: First hidden layer with ReLU activation\n",
    "        # (batch_size, 784) \u2192 (batch_size, 512)\n",
    "        x = self.fc1(x)\n",
    "        if hasattr(self, '_shapes_printed') and self._shapes_printed:\n",
    "            print(f\"After fc1 (linear): {x.shape}\")\n",
    "        x = self.relu(x)\n",
    "        if hasattr(self, '_shapes_printed') and self._shapes_printed:\n",
    "            print(f\"After relu: {x.shape} (same shape, but negative values \u2192 0)\")\n",
    "\n",
    "        # Step 3: Second hidden layer with ReLU activation\n",
    "        # (batch_size, 512) \u2192 (batch_size, 256)\n",
    "        x = self.fc2(x)\n",
    "        if hasattr(self, '_shapes_printed') and self._shapes_printed:\n",
    "            print(f\"After fc2 (linear): {x.shape}\")\n",
    "        x = self.relu(x)\n",
    "        if hasattr(self, '_shapes_printed') and self._shapes_printed:\n",
    "            print(f\"After relu: {x.shape}\")\n",
    "\n",
    "        # Step 4: Output layer (no activation - raw logits)\n",
    "        # (batch_size, 256) \u2192 (batch_size, 10)\n",
    "        x = self.fc3(x)\n",
    "        if hasattr(self, '_shapes_printed') and self._shapes_printed:\n",
    "            print(f\"Output (logits): {x.shape}\")\n",
    "            print(\"-\" * 60)\n",
    "            self._shapes_printed = False  # Only print once\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of our model\n",
    "print(\"\\nCreating the neural network...\")\n",
    "model = FashionNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b002f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\u2713 Model created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb90625d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Print model architecture\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Model Architecture:\")\n",
    "print(\"-\" * 60)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd429d9a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Calculate and display the number of parameters\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count the total number of trainable parameters in the model\"\"\"\n",
    "    total = 0\n",
    "    details = []\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if parameter.requires_grad:\n",
    "            param_count = parameter.numel()\n",
    "            total += param_count\n",
    "            details.append((name, param_count, list(parameter.shape)))\n",
    "    return total, details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c39c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params, param_details = count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c1441",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Model Parameters:\")\n",
    "print(\"-\" * 60)\n",
    "for name, count, shape in param_details:\n",
    "    print(f\"  {name:20s}: {count:>10,} parameters  {shape}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  {'TOTAL':20s}: {total_params:>10,} parameters\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3979caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Parameter Breakdown:\n",
    "- fc1 (784 \u2192 512): {(784 * 512 + 512):,} parameters\n",
    "  (784 weights per neuron \u00d7 512 neurons + 512 biases)\n",
    "\n",
    "- fc2 (512 \u2192 256): {(512 * 256 + 256):,} parameters\n",
    "  (512 weights per neuron \u00d7 256 neurons + 256 biases)\n",
    "\n",
    "- fc3 (256 \u2192 10): {(256 * 10 + 10):,} parameters\n",
    "  (256 weights per neuron \u00d7 10 neurons + 10 biases)\n",
    "\n",
    "These {total_params:,} parameters will be learned during training!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45610fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with a sample batch to verify it works\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Testing Model with Sample Batch:\")\n",
    "print(\"-\" * 60)\n",
    "model.eval()  # Set to evaluation mode\n",
    "with torch.no_grad():\n",
    "    sample_output = model(sample_batch_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSample output shape: {sample_output.shape}\")\n",
    "print(f\"  - Batch size: {sample_output.shape[0]}\")\n",
    "print(f\"  - Number of classes: {sample_output.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a76e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nFirst sample's output (logits for 10 classes):\")\n",
    "print(sample_output[0])\n",
    "print(\"\"\"\n",
    "These are raw scores (logits) for each class.\n",
    "Higher score = model thinks this class is more likely.\n",
    "We'll use softmax to convert these to probabilities later.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ec91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what the predicted class would be\n",
    "predicted_class = sample_output[0].argmax()\n",
    "print(f\"Predicted class: {predicted_class} ({class_names[predicted_class]})\")\n",
    "print(f\"Actual class: {sample_batch_labels[0]} ({class_names[sample_batch_labels[0]]})\")\n",
    "print(\"(Prediction is random at this point - model hasn't been trained yet!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ab96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 6: DEFINING LOSS FUNCTION AND OPTIMIZER\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2ad9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Loss Function: CrossEntropyLoss\n",
    "--------------------------------\n",
    "CrossEntropyLoss is the standard loss function for multi-class classification.\n",
    "\n",
    "What it does:\n",
    "1. Applies softmax to convert logits to probabilities:\n",
    "   probability(class_i) = exp(logit_i) / sum(exp(all_logits))\n",
    "\n",
    "2. Computes the negative log-likelihood:\n",
    "   loss = -log(probability_of_correct_class)\n",
    "\n",
    "Why it works:\n",
    "- If model is confident and correct: probability \u2248 1, loss \u2248 0 (good!)\n",
    "- If model is confident but wrong: probability \u2248 0, loss \u2248 \u221e (bad!)\n",
    "- Encourages model to be confident in the correct class\n",
    "\n",
    "Example:\n",
    "  True class: 2 (Pullover)\n",
    "  Model output: [0.1, 0.2, 0.6, 0.05, 0.05] (after softmax)\n",
    "  Loss = -log(0.6) \u2248 0.51\n",
    "\n",
    "  If model improves to: [0.05, 0.05, 0.85, 0.025, 0.025]\n",
    "  Loss = -log(0.85) \u2248 0.16 (lower is better!)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf48b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"\u2713 Loss function created: CrossEntropyLoss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Optimizer: Adam (Adaptive Moment Estimation)\n",
    "--------------------------------------------\n",
    "Adam is one of the most popular optimizers for deep learning.\n",
    "\n",
    "What it does:\n",
    "- Adapts the learning rate for each parameter individually\n",
    "- Combines ideas from RMSprop and SGD with momentum\n",
    "- Uses moving averages of gradients and squared gradients\n",
    "\n",
    "Why Adam?\n",
    "- Works well \"out of the box\" with default settings\n",
    "- Robust to choice of learning rate\n",
    "- Handles sparse gradients well\n",
    "- Commonly used as a default optimizer\n",
    "\n",
    "Key hyperparameters:\n",
    "- learning_rate (lr): How big a step to take (we'll use 0.001)\n",
    "  - Too high: Training unstable, might not converge\n",
    "  - Too low: Training very slow\n",
    "  - 0.001 is a good default starting point\n",
    "\n",
    "Other popular optimizers:\n",
    "- SGD: Simple, requires careful tuning\n",
    "- RMSprop: Good for RNNs\n",
    "- AdamW: Adam with better weight decay (great for transformers)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b59dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "print(f\"Setting learning rate = {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3284841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(\"\u2713 Optimizer created: Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nOptimizer configuration:\")\n",
    "print(f\"  - Algorithm: Adam\")\n",
    "print(f\"  - Learning rate: {learning_rate}\")\n",
    "print(f\"  - Parameters to optimize: {total_params:,}\")\n",
    "print(f\"  - Default beta1: 0.9 (momentum for gradients)\")\n",
    "print(f\"  - Default beta2: 0.999 (momentum for squared gradients)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b760242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 7: TRAINING THE NEURAL NETWORK\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Training Loop Overview:\n",
    "-----------------------\n",
    "Training a neural network is an iterative process:\n",
    "\n",
    "For each epoch (complete pass through training data):\n",
    "    For each batch of images:\n",
    "        1. Forward Pass: Feed images through network \u2192 get predictions\n",
    "        2. Compute Loss: Compare predictions to true labels\n",
    "        3. Backward Pass: Compute gradients (how to adjust each parameter)\n",
    "        4. Update Parameters: Adjust weights to reduce loss\n",
    "        5. Reset Gradients: Clear gradients for next iteration\n",
    "\n",
    "Key Concepts:\n",
    "-------------\n",
    "- Epoch: One complete pass through all training data\n",
    "  * We'll train for multiple epochs to learn progressively\n",
    "\n",
    "- Batch: Group of samples processed together\n",
    "  * More efficient than processing one at a time\n",
    "  * Provides more stable gradient estimates\n",
    "\n",
    "- Gradient: Direction and magnitude to adjust each parameter\n",
    "  * Computed by backpropagation\n",
    "  * Tells us how to change weights to reduce loss\n",
    "\n",
    "- optimizer.zero_grad(): Reset gradients to zero\n",
    "  * PyTorch accumulates gradients by default\n",
    "  * Must clear before each backward pass\n",
    "\n",
    "- loss.backward(): Compute gradients via backpropagation\n",
    "  * Calculates \u2202loss/\u2202weight for every parameter\n",
    "  * Uses chain rule to propagate through layers\n",
    "\n",
    "- optimizer.step(): Update parameters using gradients\n",
    "  * weights = weights - learning_rate * gradient\n",
    "  * Adam uses more sophisticated update rule\n",
    "\n",
    "Training Progress:\n",
    "------------------\n",
    "We'll track:\n",
    "- Loss per epoch (should decrease over time)\n",
    "- Accuracy on test set after each epoch (should increase)\n",
    "- Time per epoch\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 8\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  - Number of epochs: {num_epochs}\")\n",
    "print(f\"  - Batch size: {batch_size}\")\n",
    "print(f\"  - Batches per epoch: {len(train_loader)}\")\n",
    "print(f\"  - Total training steps: {num_epochs * len(train_loader):,}\")\n",
    "print(f\"  - Learning rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d04ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store metrics for visualization\n",
    "train_losses = []\n",
    "test_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470fab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING TRAINING...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3579edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training timer\n",
    "training_start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = datetime.now()\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"EPOCH {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # TRAINING PHASE\n",
    "    # -------------------------------------------------------------------------\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    print(\"\\nTraining...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # images shape: (batch_size, 1, 28, 28)\n",
    "        # labels shape: (batch_size,)\n",
    "\n",
    "        # STEP 1: Zero the gradients\n",
    "        # --------------------------\n",
    "        # Clear gradients from previous iteration\n",
    "        # PyTorch accumulates gradients, so we must reset them\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # STEP 2: Forward pass\n",
    "        # --------------------\n",
    "        # Feed images through the network to get predictions\n",
    "        outputs = model(images)  # Shape: (batch_size, 10)\n",
    "        # outputs contains raw logits for each class\n",
    "\n",
    "        # STEP 3: Compute loss\n",
    "        # --------------------\n",
    "        # Compare predictions with true labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        # CrossEntropyLoss automatically applies softmax and computes NLL\n",
    "\n",
    "        # STEP 4: Backward pass\n",
    "        # ---------------------\n",
    "        # Compute gradients using backpropagation\n",
    "        loss.backward()\n",
    "        # This computes \u2202loss/\u2202weight for every parameter in the model\n",
    "\n",
    "        # STEP 5: Update parameters\n",
    "        # --------------------------\n",
    "        # Adjust weights using computed gradients\n",
    "        optimizer.step()\n",
    "        # Adam uses gradients to update: weight = weight - lr * gradient\n",
    "\n",
    "        # Track statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Print progress every 100 batches\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            avg_loss = running_loss / (batch_idx + 1)\n",
    "            progress = (batch_idx + 1) / len(train_loader) * 100\n",
    "            print(f\"  Batch [{batch_idx + 1:>4}/{len(train_loader)}] \"\n",
    "                  f\"({progress:>5.1f}%)  |  Loss: {loss.item():.4f}  |  \"\n",
    "                  f\"Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Calculate average loss for this epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"\u2713 Training complete - Avg Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    # EVALUATION PHASE\n",
    "    # -------------------------------------------------------------------------\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    # In eval mode, layers like dropout and batch norm behave differently\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Disable gradient computation for evaluation (saves memory and computation)\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(images)  # Shape: (batch_size, 10)\n",
    "\n",
    "            # Get predicted class (index of maximum logit)\n",
    "            # outputs are logits, higher value = more confident\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # predicted shape: (batch_size,)\n",
    "\n",
    "            # Count correct predictions\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = 100 * correct / total\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"\u2713 Evaluation complete\")\n",
    "    print(f\"  Correct predictions: {correct:,} / {total:,}\")\n",
    "    print(f\"  Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Calculate epoch time\n",
    "    epoch_time = (datetime.now() - epoch_start_time).total_seconds()\n",
    "    print(f\"\\n\u23f1 Epoch completed in {epoch_time:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total training time\n",
    "total_training_time = (datetime.now() - training_start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f3ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total training time: {total_training_time:.1f} seconds \"\n",
    "      f\"({total_training_time / 60:.1f} minutes)\")\n",
    "print(f\"Average time per epoch: {total_training_time / num_epochs:.1f} seconds\")\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"  - Final training loss: {train_losses[-1]:.4f}\")\n",
    "print(f\"  - Final test accuracy: {test_accuracies[-1]:.2f}%\")\n",
    "print(f\"  - Best test accuracy: {max(test_accuracies):.2f}% \"\n",
    "      f\"(Epoch {test_accuracies.index(max(test_accuracies)) + 1})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 8: VISUALIZING TRAINING PROGRESS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9675483",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Visualizing training metrics helps us understand:\n",
    "- Is the model learning? (loss should decrease)\n",
    "- Is the model improving? (accuracy should increase)\n",
    "- Is the model overfitting? (training accuracy >> test accuracy)\n",
    "- Has training converged? (metrics plateau)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6d151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('FashionMNIST Training Progress', fontsize=16, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28212af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Training Loss\n",
    "ax1.plot(range(1, num_epochs + 1), train_losses,\n",
    "         marker='o', linewidth=2, markersize=8, color='#e74c3c')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Average Loss', fontsize=12)\n",
    "ax1.set_title('Training Loss Over Time', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_xticks(range(1, num_epochs + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ec173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate first and last points\n",
    "ax1.annotate(f'{train_losses[0]:.3f}',\n",
    "             xy=(1, train_losses[0]),\n",
    "             xytext=(10, 10),\n",
    "             textcoords='offset points',\n",
    "             fontsize=10,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7))\n",
    "ax1.annotate(f'{train_losses[-1]:.3f}',\n",
    "             xy=(num_epochs, train_losses[-1]),\n",
    "             xytext=(10, -10),\n",
    "             textcoords='offset points',\n",
    "             fontsize=10,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Test Accuracy\n",
    "ax2.plot(range(1, num_epochs + 1), test_accuracies,\n",
    "         marker='s', linewidth=2, markersize=8, color='#3498db')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Test Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_xticks(range(1, num_epochs + 1))\n",
    "ax2.set_ylim([0, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab61d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotate best accuracy\n",
    "best_acc_epoch = test_accuracies.index(max(test_accuracies)) + 1\n",
    "ax2.annotate(f'Best: {max(test_accuracies):.2f}%',\n",
    "             xy=(best_acc_epoch, max(test_accuracies)),\n",
    "             xytext=(10, -15),\n",
    "             textcoords='offset points',\n",
    "             fontsize=10,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', facecolor='lightgreen', alpha=0.7),\n",
    "             arrowprops=dict(arrowstyle='->', color='black', lw=1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e325a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "progress_path = os.path.join(data_dir, 'training_progress.png')\n",
    "plt.savefig(progress_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"\u2713 Training progress plots saved to: {progress_path}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c48c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary statistics\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Training Metrics Summary:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"\\nLoss per epoch:\")\n",
    "for i, loss in enumerate(train_losses, 1):\n",
    "    print(f\"  Epoch {i}: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f094eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAccuracy per epoch:\")\n",
    "for i, acc in enumerate(test_accuracies, 1):\n",
    "    marker = \" \u2b50\" if acc == max(test_accuracies) else \"\"\n",
    "    print(f\"  Epoch {i}: {acc:.2f}%{marker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab37e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 9: MAKING PREDICTIONS AND VISUALIZING RESULTS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef88b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Now let's see how our trained model performs on individual images!\n",
    "\n",
    "We'll:\n",
    "1. Get predictions on test images\n",
    "2. Show the images with predicted vs actual labels\n",
    "3. Highlight correct predictions (green) and incorrect predictions (red)\n",
    "4. Display the model's confidence (probability) for each prediction\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b319526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test images\n",
    "test_images, test_labels = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ddaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nGetting predictions for {len(test_images)} test images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ab3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_images)\n",
    "    # outputs shape: (batch_size, 10) - logits for each class\n",
    "\n",
    "    # Convert logits to probabilities using softmax\n",
    "    probabilities = F.softmax(outputs, dim=1)\n",
    "    # probabilities shape: (batch_size, 10)\n",
    "    # Each row sums to 1.0\n",
    "\n",
    "    # Get predicted class and confidence\n",
    "    confidences, predictions = torch.max(probabilities, 1)\n",
    "    # predictions: predicted class index\n",
    "    # confidences: probability of predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\u2713 Predictions complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf0c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show prediction details for first 5 images\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Sample Predictions (first 5 images):\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(5):\n",
    "    pred_class = predictions[i].item()\n",
    "    true_class = test_labels[i].item()\n",
    "    confidence = confidences[i].item() * 100\n",
    "    correct = \"\u2713\" if pred_class == true_class else \"\u2717\"\n",
    "\n",
    "    print(f\"\\nImage {i + 1}: {correct}\")\n",
    "    print(f\"  Predicted: {class_names[pred_class]} ({confidence:.1f}% confidence)\")\n",
    "    print(f\"  Actual: {class_names[true_class]}\")\n",
    "\n",
    "    if pred_class == true_class:\n",
    "        print(f\"  Status: Correct! \ud83c\udf89\")\n",
    "    else:\n",
    "        print(f\"  Status: Incorrect \u274c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a8cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "fig.suptitle('Model Predictions on Test Set\\n'\n",
    "             'Green = Correct, Red = Incorrect',\n",
    "             fontsize=16, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def82df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Creating visualization of predictions...\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea50a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "incorrect_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc813ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, ax in enumerate(axes.flat):\n",
    "    if idx >= len(test_images):\n",
    "        ax.axis('off')\n",
    "        continue\n",
    "\n",
    "    # Get image and denormalize for display\n",
    "    image = test_images[idx].squeeze()  # Remove channel dimension\n",
    "    image = image * 0.5 + 0.5  # Denormalize from [-1, 1] to [0, 1]\n",
    "\n",
    "    # Get prediction and true label\n",
    "    pred_class = predictions[idx].item()\n",
    "    true_class = test_labels[idx].item()\n",
    "    confidence = confidences[idx].item()\n",
    "\n",
    "    # Check if correct\n",
    "    is_correct = (pred_class == true_class)\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "    else:\n",
    "        incorrect_count += 1\n",
    "\n",
    "    # Display image\n",
    "    ax.imshow(image, cmap='gray')\n",
    "\n",
    "    # Set title color based on correctness\n",
    "    title_color = 'green' if is_correct else 'red'\n",
    "    title = f'Pred: {class_names[pred_class]}\\n({confidence*100:.0f}%)'\n",
    "    if not is_correct:\n",
    "        title += f'\\nTrue: {class_names[true_class]}'\n",
    "\n",
    "    ax.set_title(title, fontsize=8, color=title_color, fontweight='bold')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ddd915",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "predictions_path = os.path.join(data_dir, 'model_predictions.png')\n",
    "plt.savefig(predictions_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"\u2713 Predictions visualization saved to: {predictions_path}\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bc2016",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nVisualization shows {correct_count} correct and {incorrect_count} incorrect \"\n",
    "      f\"predictions\")\n",
    "print(f\"Accuracy on this batch: {correct_count / (correct_count + incorrect_count) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 10: ANALYZING MODEL PERFORMANCE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Let's compute detailed performance metrics to understand:\n",
    "- Which classes the model predicts well\n",
    "- Which classes are confused with each other\n",
    "- Overall model performance\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a4917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on entire test set\n",
    "print(\"\\nEvaluating model on entire test set...\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "all_labels = []\n",
    "all_confidences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c659551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        confidences, predictions = torch.max(probabilities, 1)\n",
    "\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_confidences.extend(confidences.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5742f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "all_confidences = np.array(all_confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\u2713 Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7cb8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-class accuracy\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Per-Class Performance:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Class':<15} {'Correct':<10} {'Total':<10} {'Accuracy':<10} {'Avg Confidence'}\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e5f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_idx in range(len(class_names)):\n",
    "    # Find all instances of this class\n",
    "    class_mask = (all_labels == class_idx)\n",
    "    class_predictions = all_predictions[class_mask]\n",
    "    class_true_labels = all_labels[class_mask]\n",
    "    class_confidences = all_confidences[class_mask]\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct = (class_predictions == class_true_labels).sum()\n",
    "    total = len(class_true_labels)\n",
    "    accuracy = correct / total * 100 if total > 0 else 0\n",
    "    avg_confidence = class_confidences.mean() * 100\n",
    "\n",
    "    print(f\"{class_names[class_idx]:<15} {correct:<10} {total:<10} \"\n",
    "          f\"{accuracy:>6.2f}%    {avg_confidence:>6.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics\n",
    "overall_accuracy = (all_predictions == all_labels).sum() / len(all_labels) * 100\n",
    "avg_confidence = all_confidences.mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9832f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-\" * 60)\n",
    "print(f\"{'OVERALL':<15} {(all_predictions == all_labels).sum():<10} \"\n",
    "      f\"{len(all_labels):<10} {overall_accuracy:>6.2f}%    {avg_confidence:>6.1f}%\")\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba1eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most confident correct and incorrect predictions\n",
    "correct_mask = all_predictions == all_labels\n",
    "incorrect_mask = ~correct_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_confident_correct_idx = np.argmax(all_confidences * correct_mask)\n",
    "most_confident_incorrect_idx = np.argmax(all_confidences * incorrect_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f80361",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"-\" * 60)\n",
    "print(\"Interesting Predictions:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nMost confident CORRECT prediction:\")\n",
    "print(f\"  Predicted: {class_names[all_predictions[most_confident_correct_idx]]}\")\n",
    "print(f\"  Actual: {class_names[all_labels[most_confident_correct_idx]]}\")\n",
    "print(f\"  Confidence: {all_confidences[most_confident_correct_idx] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdadbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nMost confident INCORRECT prediction:\")\n",
    "print(f\"  Predicted: {class_names[all_predictions[most_confident_incorrect_idx]]}\")\n",
    "print(f\"  Actual: {class_names[all_labels[most_confident_incorrect_idx]]}\")\n",
    "print(f\"  Confidence: {all_confidences[most_confident_incorrect_idx] * 100:.2f}%\")\n",
    "print(\"  (This might indicate similar-looking items!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aae519",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "\ud83c\udf89 Congratulations! You've successfully trained a neural network! \ud83c\udf89\n",
    "\n",
    "Model Performance:\n",
    "------------------\n",
    "Final Test Accuracy: {overall_accuracy:.2f}%\n",
    "Average Confidence: {avg_confidence:.1f}%\n",
    "Training Time: {total_training_time / 60:.1f} minutes\n",
    "\n",
    "What We Learned:\n",
    "----------------\n",
    "\u2713 How to load and preprocess image datasets\n",
    "\u2713 How to create DataLoaders for efficient batching\n",
    "\u2713 How to build a multi-layer neural network with PyTorch\n",
    "\u2713 How to implement a training loop with forward and backward passes\n",
    "\u2713 How to evaluate model performance on a test set\n",
    "\u2713 How to visualize training progress and predictions\n",
    "\u2713 How to analyze per-class performance\n",
    "\n",
    "Model Architecture:\n",
    "-------------------\n",
    "- Input: 28\u00d728 grayscale images (784 pixels)\n",
    "- Hidden Layer 1: 512 neurons with ReLU\n",
    "- Hidden Layer 2: 256 neurons with ReLU\n",
    "- Output: 10 classes (clothing categories)\n",
    "- Total Parameters: {total_params:,}\n",
    "\n",
    "Training Configuration:\n",
    "-----------------------\n",
    "- Epochs: {num_epochs}\n",
    "- Batch Size: {batch_size}\n",
    "- Learning Rate: {learning_rate}\n",
    "- Optimizer: Adam\n",
    "- Loss Function: CrossEntropyLoss\n",
    "\n",
    "Files Created:\n",
    "--------------\n",
    "1. {os.path.join(data_dir, 'sample_images.png')}\n",
    "   - Sample images from the dataset\n",
    "\n",
    "2. {os.path.join(data_dir, 'training_progress.png')}\n",
    "   - Loss and accuracy curves over training\n",
    "\n",
    "3. {os.path.join(data_dir, 'model_predictions.png')}\n",
    "   - Visualization of model predictions\n",
    "\n",
    "Next Steps:\n",
    "-----------\n",
    "- Try different architectures (more/fewer layers, different sizes)\n",
    "- Experiment with learning rate and batch size\n",
    "- Add dropout for regularization\n",
    "- Try different optimizers (SGD, RMSprop)\n",
    "- Implement early stopping\n",
    "- Save and load the trained model\n",
    "- Use convolutional layers (CNNs) for better image performance\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464415d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRACTICE PROBLEMS\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b029fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Test your understanding with these exercises:\n",
    "\n",
    "1. EASY: Experiment with hyperparameters\n",
    "   - Change the learning rate to 0.0001 and 0.01\n",
    "   - Change the batch size to 32 and 128\n",
    "   - How does this affect training speed and accuracy?\n",
    "\n",
    "2. EASY: Add more epochs\n",
    "   - Train for 15-20 epochs instead of 8\n",
    "   - Does the accuracy keep improving or plateau?\n",
    "   - Plot the learning curves to visualize this\n",
    "\n",
    "3. MEDIUM: Modify the architecture\n",
    "   - Add a third hidden layer with 128 neurons\n",
    "   - Try different layer sizes (e.g., 1024 \u2192 512 \u2192 256 \u2192 128 \u2192 10)\n",
    "   - Try a smaller network (256 \u2192 128 \u2192 10)\n",
    "   - How does this affect number of parameters and performance?\n",
    "\n",
    "4. MEDIUM: Add dropout for regularization\n",
    "   - Add nn.Dropout(0.2) after each ReLU activation\n",
    "   - This randomly sets 20% of neurons to zero during training\n",
    "   - Does this improve or hurt performance?\n",
    "   - Hint: Remember dropout behaves differently in train vs eval mode!\n",
    "\n",
    "5. MEDIUM: Implement model saving and loading\n",
    "   - Save the trained model: torch.save(model.state_dict(), 'model.pth')\n",
    "   - Load it later: model.load_state_dict(torch.load('model.pth'))\n",
    "   - Verify it produces the same predictions\n",
    "\n",
    "6. HARD: Create a confusion matrix\n",
    "   - Build a 10\u00d710 matrix showing predicted vs actual classes\n",
    "   - Which classes are most often confused with each other?\n",
    "   - Visualize it as a heatmap using matplotlib\n",
    "   - Hint: Use a nested loop over all class pairs\n",
    "\n",
    "7. HARD: Implement learning rate scheduling\n",
    "   - Start with high learning rate, decrease over time\n",
    "   - Use torch.optim.lr_scheduler.StepLR or ReduceLROnPlateau\n",
    "   - Does this improve final accuracy?\n",
    "\n",
    "8. HARD: Try a different optimizer\n",
    "   - Replace Adam with SGD with momentum:\n",
    "     optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "   - How does training differ?\n",
    "   - Which converges faster?\n",
    "\n",
    "9. ADVANCED: Implement early stopping\n",
    "   - Stop training if test accuracy doesn't improve for 3 epochs\n",
    "   - Save the best model (highest test accuracy)\n",
    "   - This prevents overfitting!\n",
    "\n",
    "10. ADVANCED: Build a CNN instead\n",
    "    - Replace the fully connected layers with convolutional layers\n",
    "    - Use nn.Conv2d, nn.MaxPool2d, nn.BatchNorm2d\n",
    "    - CNNs are much better for image data!\n",
    "    - Can you beat the current accuracy?\n",
    "\n",
    "Challenge:\n",
    "----------\n",
    "Can you get the test accuracy above 90%? Try combining multiple\n",
    "improvements: better architecture, dropout, learning rate scheduling,\n",
    "data augmentation, etc.\n",
    "\n",
    "Remember:\n",
    "---------\n",
    "- Always print shapes when debugging\n",
    "- Visualize your results to understand what's happening\n",
    "- Experiment and have fun!\n",
    "- Machine learning is about iteration and experimentation\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed2881",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Lesson completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4400a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\ud83d\ude80 You're now ready to build real deep learning models with PyTorch!\")\n",
    "print(\"This is just the beginning - there's so much more to explore!\\n\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}