{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Data Management - Code Exercise\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f7738",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "Lesson 7: Data Management - Downloading Datasets and Building Custom PyTorch Datasets\n",
    "================================================================================\n",
    "\n",
    "Source: Based on TK's article on building custom PyTorch datasets\n",
    "Topic: Learn how to download datasets, extract archives, and create custom Dataset classes\n",
    "\n",
    "Learning Objectives:\n",
    "1. Download datasets programmatically with progress bars\n",
    "2. Extract compressed archives (tar.gz files)\n",
    "3. Build custom PyTorch Dataset classes\n",
    "4. Load and visualize dataset samples\n",
    "5. Understand the Dataset interface (__init__, __len__, __getitem__)\n",
    "\n",
    "Dataset: Oxford Flowers 102\n",
    "- 102 flower categories\n",
    "- 8,189 images\n",
    "- Source: https://www.robots.ox.ac.uk/~vgg/data/flowers/102/\n",
    "================================================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8374bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2194b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LESSON 7: Data Management - Custom PyTorch Datasets\")\n",
    "print(\"=\" * 80)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# IMPORTS\n",
    "# ================================================================================\n",
    "print(\"Importing required libraries...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ac367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import tarfile\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372b9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\u2713 All libraries imported successfully\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# SECTION 1: SETTING UP DATA DIRECTORY\n",
    "# ================================================================================\n",
    "print(\"-\" * 80)\n",
    "print(\"SECTION 1: Setting Up Data Directory\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e2a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the shared data directory (consistent across all lessons)\n",
    "DATA_DIR = \"/Users/zack/dev/ml-refresher/data/oxford_flowers\"\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e6cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "# exist_ok=True means no error if directory already exists (idempotent operation)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "print(f\"\u2713 Data directory created/verified: {DATA_DIR}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# SECTION 2: DOWNLOADING THE IMAGES\n",
    "# ================================================================================\n",
    "print(\"-\" * 80)\n",
    "print(\"SECTION 2: Downloading the Images Dataset\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563a03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the Oxford Flowers 102 dataset (images)\n",
    "image_url = \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\"\n",
    "tgz_path = os.path.join(DATA_DIR, \"102flowers.tgz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07dd6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Image dataset URL: {image_url}\")\n",
    "print(f\"Download destination: {tgz_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the file already exists to avoid re-downloading\n",
    "if os.path.exists(tgz_path):\n",
    "    print(f\"\u2713 Image archive already exists, skipping download\")\n",
    "else:\n",
    "    print(\"Downloading image archive...\")\n",
    "    try:\n",
    "        # Use stream=True to download in chunks (memory efficient for large files)\n",
    "        response = requests.get(image_url, stream=True)\n",
    "        response.raise_for_status()  # Raise exception for bad status codes\n",
    "\n",
    "        # Get total file size from HTTP headers (for progress bar)\n",
    "        total_size = int(response.headers.get(\"content-length\", 0))\n",
    "        print(f\"Total size: {total_size / (1024*1024):.2f} MB\")\n",
    "\n",
    "        # Download with progress bar using tqdm\n",
    "        # iter_content() downloads in chunks (1024 bytes = 1 KB)\n",
    "        with open(tgz_path, \"wb\") as file:\n",
    "            with tqdm(\n",
    "                total=total_size // 1024,  # Total chunks\n",
    "                unit=\"KB\",\n",
    "                desc=\"Downloading images\",\n",
    "                ncols=80\n",
    "            ) as pbar:\n",
    "                for data in response.iter_content(chunk_size=1024):\n",
    "                    file.write(data)\n",
    "                    pbar.update(1)\n",
    "\n",
    "        print(f\"\u2713 Image archive downloaded successfully\")\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\u2717 Error downloading image archive: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f13fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# SECTION 3: EXTRACTING THE ARCHIVE\n",
    "# ================================================================================\n",
    "print(\"-\" * 80)\n",
    "print(\"SECTION 3: Extracting the Image Archive\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where images will be extracted (inside DATA_DIR/jpg/)\n",
    "jpg_dir = os.path.join(DATA_DIR, \"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f76d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if already extracted\n",
    "if os.path.exists(jpg_dir) and len(os.listdir(jpg_dir)) > 0:\n",
    "    print(f\"\u2713 Images already extracted to: {jpg_dir}\")\n",
    "    print(f\"  Found {len(os.listdir(jpg_dir))} files\")\n",
    "else:\n",
    "    print(f\"Extracting archive to: {DATA_DIR}\")\n",
    "    try:\n",
    "        # Open and extract tar.gz archive\n",
    "        # 'r:gz' means read mode with gzip compression\n",
    "        with tarfile.open(tgz_path, \"r:gz\") as tar:\n",
    "            # extractall() extracts all files to the specified directory\n",
    "            tar.extractall(DATA_DIR)\n",
    "\n",
    "        print(f\"\u2713 Archive extracted successfully\")\n",
    "        if os.path.exists(jpg_dir):\n",
    "            print(f\"  Extracted {len(os.listdir(jpg_dir))} image files\")\n",
    "\n",
    "    except tarfile.TarError as e:\n",
    "        print(f\"\u2717 Error extracting archive: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114a8298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8110fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# SECTION 4: DOWNLOADING THE LABELS\n",
    "# ================================================================================\n",
    "print(\"-\" * 80)\n",
    "print(\"SECTION 4: Downloading the Labels\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f03287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL for the labels (MATLAB format)\n",
    "labels_url = \"https://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat\"\n",
    "labels_path = os.path.join(DATA_DIR, \"imagelabels.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb64c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Labels URL: {labels_url}\")\n",
    "print(f\"Download destination: {labels_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c457a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if labels already exist\n",
    "if os.path.exists(labels_path):\n",
    "    print(f\"\u2713 Labels file already exists, skipping download\")\n",
    "else:\n",
    "    print(\"Downloading labels file...\")\n",
    "    try:\n",
    "        # Download labels file (smaller, so we can download all at once)\n",
    "        response = requests.get(labels_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        total_size = int(response.headers.get(\"content-length\", 0))\n",
    "        print(f\"Total size: {total_size / 1024:.2f} KB\")\n",
    "\n",
    "        # Download with progress bar\n",
    "        with open(labels_path, \"wb\") as file:\n",
    "            with tqdm(\n",
    "                total=total_size // 1024,\n",
    "                unit=\"KB\",\n",
    "                desc=\"Downloading labels\",\n",
    "                ncols=80\n",
    "            ) as pbar:\n",
    "                for data in response.iter_content(chunk_size=1024):\n",
    "                    file.write(data)\n",
    "                    pbar.update(1)\n",
    "\n",
    "        print(f\"\u2713 Labels file downloaded successfully\")\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"\u2717 Error downloading labels: {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf772d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f557532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# SECTION 5: BUILDING THE CUSTOM DATASET CLASS\n",
    "# ================================================================================\n",
    "print(\"-\" * 80)\n",
    "print(\"SECTION 5: Building the Custom Dataset Class\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c335f732",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "PyTorch Dataset Interface:\n",
    "- Must inherit from torch.utils.data.Dataset\n",
    "- Must implement three methods:\n",
    "  1. __init__(): Initialize dataset, load metadata\n",
    "  2. __len__(): Return total number of samples\n",
    "  3. __getitem__(idx): Return the sample at index idx\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83926a7c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class OxfordFlowersDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset for Oxford Flowers 102.\n",
    "\n",
    "    The Oxford Flowers 102 dataset contains images of 102 flower categories.\n",
    "    Images are numbered from image_00001.jpg to image_08189.jpg.\n",
    "    Labels are stored in a MATLAB .mat file.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str): Root directory containing the dataset\n",
    "        transform (callable, optional): Optional transform to apply to images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initialize the dataset by loading metadata and labels.\n",
    "\n",
    "        This method runs once when you create the dataset object.\n",
    "        It should load any metadata (file paths, labels) but NOT load images\n",
    "        (images are loaded on-demand in __getitem__).\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.img_dir = os.path.join(root_dir, \"jpg\")\n",
    "        self.transform = transform\n",
    "\n",
    "        # Load labels from MATLAB file using scipy\n",
    "        labels_path = os.path.join(root_dir, \"imagelabels.mat\")\n",
    "        labels_mat = scipy.io.loadmat(labels_path)\n",
    "\n",
    "        # Labels are stored in the \"labels\" key as a 2D array\n",
    "        # Shape: (1, 8189) - we take [0] to get 1D array\n",
    "        # Labels are 1-indexed (1-102), so we subtract 1 for 0-indexing (0-101)\n",
    "        self.labels = labels_mat[\"labels\"][0] - 1\n",
    "\n",
    "        print(f\"  Initialized OxfordFlowersDataset\")\n",
    "        print(f\"  - Root directory: {root_dir}\")\n",
    "        print(f\"  - Image directory: {self.img_dir}\")\n",
    "        print(f\"  - Number of samples: {len(self.labels)}\")\n",
    "        print(f\"  - Label range: {self.labels.min()} to {self.labels.max()}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the total number of samples in the dataset.\n",
    "\n",
    "        This is used by DataLoader to know how many samples exist.\n",
    "        Called when you use len(dataset).\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Load and return a sample from the dataset at the given index.\n",
    "\n",
    "        This method is called every time you access dataset[idx].\n",
    "        It should load the image from disk and return it with its label.\n",
    "\n",
    "        Args:\n",
    "            idx (int): Index of the sample to load (0 to len-1)\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, label) where image is a PIL Image and label is an int\n",
    "        \"\"\"\n",
    "        # Construct image filename (images are named image_00001.jpg to image_08189.jpg)\n",
    "        # :05d means zero-pad to 5 digits (e.g., 1 becomes 00001)\n",
    "        image_name = f\"image_{idx + 1:05d}.jpg\"\n",
    "        image_path = os.path.join(self.img_dir, image_name)\n",
    "\n",
    "        # Load image using PIL (Pillow)\n",
    "        # PIL images are in (width, height, channels) format\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Get the corresponding label\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Apply transforms if provided (e.g., resize, normalize, to tensor)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3940eaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\u2713 OxfordFlowersDataset class defined\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de215bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# SECTION 6: USING THE DATASET\n",
    "# ================================================================================\n",
    "print(\"-\" * 80)\n",
    "print(\"SECTION 6: Using the Dataset\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be35c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of our custom dataset\n",
    "print(\"Creating dataset instance...\")\n",
    "dataset = OxfordFlowersDataset(DATA_DIR)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f302c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of the dataset\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "print(f\"(This tells us how many samples are in the dataset)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ce00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access individual samples\n",
    "print(\"Accessing dataset samples:\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf820a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first sample (index 0)\n",
    "img, label = dataset[0]\n",
    "print(f\"Sample 0:\")\n",
    "print(f\"  - Image type: {type(img)}\")\n",
    "print(f\"  - Image mode: {img.mode}\")  # RGB, L (grayscale), etc.\n",
    "print(f\"  - Image size: {img.size}\")  # (width, height)\n",
    "print(f\"  - Label: {label} (class {label + 1} in 1-indexed format)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029eba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a few more samples to see variety\n",
    "for idx in [10, 100, 1000]:\n",
    "    img, label = dataset[idx]\n",
    "    print(f\"Sample {idx}:\")\n",
    "    print(f\"  - Image size: {img.size}\")\n",
    "    print(f\"  - Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfab7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd438e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show label distribution (how many images per class)\n",
    "print(\"Label distribution:\")\n",
    "print(\"-\" * 40)\n",
    "unique_labels, counts = np.unique(dataset.labels, return_counts=True)\n",
    "print(f\"Number of classes: {len(unique_labels)}\")\n",
    "print(f\"Images per class (min/max/mean): {counts.min()}/{counts.max()}/{counts.mean():.1f}\")\n",
    "print(f\"(Note: This dataset is roughly balanced across classes)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187bda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# SECTION 7: VISUALIZING IMAGES\n",
    "# ================================================================================\n",
    "print(\"-\" * 80)\n",
    "print(\"SECTION 7: Visualizing Images\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13fae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating visualization of sample images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with subplots to show multiple images\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle(\"Oxford Flowers 102 - Sample Images\", fontsize=16, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten axes array for easier iteration\n",
    "axes = axes.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf45c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample some random indices\n",
    "np.random.seed(42)  # For reproducibility\n",
    "sample_indices = np.random.choice(len(dataset), size=6, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61faa227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display each sample\n",
    "for idx, ax in enumerate(axes):\n",
    "    # Get image and label\n",
    "    img, label = dataset[sample_indices[idx]]\n",
    "\n",
    "    # Convert PIL image to numpy array for matplotlib\n",
    "    img_array = np.array(img)\n",
    "\n",
    "    # Display image\n",
    "    ax.imshow(img_array)\n",
    "    ax.set_title(f\"Class: {label} | Size: {img.size[0]}x{img.size[1]}\", fontsize=10)\n",
    "    ax.axis(\"off\")  # Hide axis ticks and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ed1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942fe665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure instead of showing it (since this is a script)\n",
    "viz_path = os.path.join(DATA_DIR, \"sample_visualization.png\")\n",
    "plt.savefig(viz_path, dpi=100, bbox_inches='tight')\n",
    "print(f\"\u2713 Visualization saved to: {viz_path}\")\n",
    "print(f\"  (Use plt.show() instead of savefig() to display interactively)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31491e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Display a single large image\n",
    "print(\"Displaying a single sample image:\")\n",
    "img, label = dataset[0]\n",
    "print(f\"  - Sample index: 0\")\n",
    "print(f\"  - Label (class): {label}\")\n",
    "print(f\"  - Image dimensions: {img.size[0]}x{img.size[1]}\")\n",
    "print(f\"  - Image mode: {img.mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3946d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create single image visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.title(f\"Oxford Flowers Sample - Class {label}\", fontsize=14, fontweight='bold')\n",
    "plt.imshow(np.array(img))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0146ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_viz_path = os.path.join(DATA_DIR, \"single_sample.png\")\n",
    "plt.savefig(single_viz_path, dpi=100, bbox_inches='tight')\n",
    "print(f\"\u2713 Single sample visualization saved to: {single_viz_path}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54269fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================================\n",
    "# SECTION 8: PRACTICE PROBLEMS\n",
    "# ================================================================================\n",
    "print(\"-\" * 80)\n",
    "print(\"SECTION 8: Practice Problems\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ca9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Practice these exercises to deepen your understanding:\n",
    "\n",
    "PROBLEM 1: Add Train/Test Split\n",
    "-------------------------------\n",
    "Modify the OxfordFlowersDataset class to support train/test/validation splits.\n",
    "The dataset provides setid.mat with predefined splits.\n",
    "\n",
    "Hints:\n",
    "- Download setid.mat from the same URL base\n",
    "- Load it with scipy.io.loadmat()\n",
    "- Add a 'split' parameter to __init__ ('train', 'val', or 'test')\n",
    "- Filter self.labels to only include samples in the chosen split\n",
    "- Update __getitem__ to use the correct indices\n",
    "\n",
    "Example usage:\n",
    "    train_dataset = OxfordFlowersDataset(DATA_DIR, split='train')\n",
    "    test_dataset = OxfordFlowersDataset(DATA_DIR, split='test')\n",
    "\n",
    "\n",
    "PROBLEM 2: Add Transforms Support\n",
    "----------------------------------\n",
    "Enhance the dataset to work with torchvision transforms.\n",
    "\n",
    "Hints:\n",
    "- Import torchvision.transforms as transforms\n",
    "- Create a transform pipeline:\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "- Pass transform to the dataset: dataset = OxfordFlowersDataset(DATA_DIR, transform)\n",
    "- The transform is already supported in __getitem__!\n",
    "\n",
    "Test it:\n",
    "    img, label = dataset[0]\n",
    "    print(f\"Transformed image shape: {img.shape}\")  # Should be torch.Size([3, 224, 224])\n",
    "\n",
    "\n",
    "PROBLEM 3: Create a DataLoader\n",
    "-------------------------------\n",
    "Use PyTorch's DataLoader to batch and shuffle the dataset.\n",
    "\n",
    "Hints:\n",
    "- Import: from torch.utils.data import DataLoader\n",
    "- Create DataLoader with batching and shuffling:\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4,  # Parallel data loading\n",
    "        pin_memory=True  # Faster transfer to GPU\n",
    "    )\n",
    "- Iterate through batches:\n",
    "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "        print(f\"Batch {batch_idx}: images shape {images.shape}, labels shape {labels.shape}\")\n",
    "        if batch_idx == 0:  # Just show first batch\n",
    "            break\n",
    "\n",
    "Expected output:\n",
    "    Batch 0: images shape torch.Size([32, 3, 224, 224]), labels shape torch.Size([32])\n",
    "\n",
    "\n",
    "BONUS CHALLENGE: Custom Collate Function\n",
    "-----------------------------------------\n",
    "Images in this dataset have different sizes. When batching, this causes issues.\n",
    "Write a custom collate_fn that handles variable-sized images.\n",
    "\n",
    "Hints:\n",
    "- Define: def custom_collate(batch): ...\n",
    "- Option 1: Resize all images to the same size\n",
    "- Option 2: Pad images to the largest size in the batch\n",
    "- Option 3: Return a list instead of a tensor for images\n",
    "- Pass to DataLoader: DataLoader(dataset, collate_fn=custom_collate)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c38d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"LESSON COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Summary:\")\n",
    "print(\"\u2713 Downloaded Oxford Flowers 102 dataset\")\n",
    "print(\"\u2713 Extracted images and loaded labels\")\n",
    "print(\"\u2713 Built custom PyTorch Dataset class\")\n",
    "print(\"\u2713 Accessed and visualized dataset samples\")\n",
    "print(\"\u2713 Understood the Dataset interface (__init__, __len__, __getitem__)\")\n",
    "print()\n",
    "print(\"Next Steps:\")\n",
    "print(\"1. Complete the practice problems above\")\n",
    "print(\"2. Try using torch.utils.data.DataLoader with this dataset\")\n",
    "print(\"3. Experiment with different transforms (resize, normalize, augmentation)\")\n",
    "print(\"4. Build a model to classify these flowers!\")\n",
    "print()\n",
    "print(f\"Data location: {DATA_DIR}\")\n",
    "print(f\"Visualizations saved in: {DATA_DIR}\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}